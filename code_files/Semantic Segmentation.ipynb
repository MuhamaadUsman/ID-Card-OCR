{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                    # import OS module for operating system dependent functionality\n",
    "import numpy as np           # import NumPy library for array computing \n",
    "import pandas as pd          # import Pandas library for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # import Matplotlib library for data visualization\n",
    "from PIL import Image        # import Image module from Python Imaging Library to open and manipulate images\n",
    "import cv2 as cv             # import OpenCV library for computer vision tasks\n",
    "import torch                 # import PyTorch library for machine learning\n",
    "import json                  # import JSON module to work with JSON data\n",
    "import torchvision          # import TorchVision library for computer vision tasks\n",
    "from engine import train_one_epoch, evaluate  # import train_one_epoch and evaluate functions from engine module\n",
    "import utils                 # import utils module for various utility functions\n",
    "import random                # import random module for generating random numbers and sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767119a",
   "metadata": {},
   "source": [
    "# Image Data Extraction and Class Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38caf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Class for Data Extraction and Processing\n",
    "\n",
    "class OCRDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        # Constructor for the class\n",
    "        # Sets the root directory where the images and JSON file is stored\n",
    "        self.root = root\n",
    "\n",
    "        # Loads the list of image files and removes the last element as it is a JSON file\n",
    "        self.imgs = list(os.listdir(root))[:-1]\n",
    "\n",
    "        # Loads the JSON file containing the annotations for the images\n",
    "        self.data = json.load(open(os.path.join(self.root, 'result.json')))\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Load Images\n",
    "        image_id = self.data['images'][idx]['id']\n",
    "        image_path = self.data['images'][idx]['file_name'][10:]\n",
    "\n",
    "        # Extracting the image from the file path\n",
    "        image = Image.open(os.path.join(self.root, image_path)).convert('RGB')\n",
    "\n",
    "        # Extracting the image information from the JSON file except MASK\n",
    "        target = {}\n",
    "        target['boxes'] = self.data['annotations'][idx]['bbox']\n",
    "        target['labels'] = self.data['annotations'][idx]['category_id']+1\n",
    "        target['image_id'] = self.data['annotations'][idx]['image_id']\n",
    "        target['area'] = self.data['annotations'][idx]['area']\n",
    "        target['iscrowd'] = self.data['annotations'][idx]['iscrowd']\n",
    "        \n",
    "        # Creating a numpy array containing four points, which form a rectangle\n",
    "        # Each point is extracted from the JSON file using its corresponding index, \n",
    "        # and its coordinates are converted to integers using the int() function\n",
    "        pts = np.array([[int(self.data['annotations'][idx]['segmentation'][0][0]), int(self.data['annotations'][idx]['segmentation'][0][1])],\n",
    "                        [int(self.data['annotations'][idx]['segmentation'][0][2]), int(self.data['annotations'][idx]['segmentation'][0][3])],\n",
    "                        [int(self.data['annotations'][idx]['segmentation'][0][4]), int(self.data['annotations'][idx]['segmentation'][0][5])],\n",
    "                        [int(self.data['annotations'][idx]['segmentation'][0][6]), int(self.data['annotations'][idx]['segmentation'][0][7])]])\n",
    "\n",
    "        # Sorting the points from left to right based on their x-coordinates\n",
    "        xSorted = pts[np.argsort(pts[:,0]),:]\n",
    "\n",
    "        # Splitting the sorted points into left-most and right-most points\n",
    "        leftMost = xSorted[:2,:]\n",
    "        rightMost = xSorted[2:,:]\n",
    "\n",
    "        # Sorting the left-most points from top to bottom based on their y-coordinates\n",
    "        leftMost = leftMost[np.argsort(leftMost[:,1]), :]\n",
    "\n",
    "        # Extracting the top-left and bottom-left points from the sorted left-most points\n",
    "        (tl, bl) = leftMost\n",
    "\n",
    "        # Calculating the distances between the top-left point and the two right-most points,\n",
    "        # and then extracting the right-most point with the greatest distance\n",
    "        D = dist.cdist(tl[np.newaxis], rightMost, 'euclidean')[0]\n",
    "        (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "        # Creating an array of keypoints for the rectangle, where each keypoint \n",
    "        # is represented as a 3-element array containing the x-coordinate, y-coordinate,\n",
    "        # and a flag indicating the keypoint visibility (1 = visible, 0 = invisible)\n",
    "        # The coordinates of each keypoint are calculated based on the extracted \n",
    "        # top-left, top-right, bottom-right, and bottom-left points of the rectangle\n",
    "        target['keypoints'] = np.array([[max(tl[0],0), max(tl[1],0),1],\n",
    "                                        [max(tr[0],0), max(tr[1],0),1],\n",
    "                                        [max(br[0],0), max(br[1],0),1],\n",
    "                                        [max(bl[0],0), max(bl[1],0),1]])\n",
    "\n",
    "\n",
    "        # Calculating the (x1,y1) and (x2,y2) of the bounding boxes from width and height\n",
    "        target['boxes'] = [target['boxes'][0], target['boxes'][1], target['boxes'][0]+target['boxes'][2], target['boxes'][1]+target['boxes'][3]]\n",
    "        \n",
    "        # Reshaping\n",
    "        target['boxes'] = np.expand_dims(target['boxes'], axis=0)\n",
    "\n",
    "        # Converting all arrays to tensors for compatibility with PyTorch\n",
    "        target['boxes'] = torch.as_tensor(target['boxes'], dtype=torch.float32)\n",
    "        target['labels'] = torch.tensor([target['labels']], dtype=torch.int64)\n",
    "        target['image_id'] = torch.tensor([target['image_id']])\n",
    "        target['area'] = torch.tensor([target['area']])\n",
    "        target['iscrowd'] = torch.tensor([target['iscrowd']], dtype=torch.int64)\n",
    "        target['keypoints'] = torchl.tensor([target['keypoints']], dtype=torch.float32)\n",
    "\n",
    "        return image, target\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining direcotries and loading the json file\n",
    "root = 'path/to/images'\n",
    "json_file = 'path/to/saved/result.json'\n",
    "data = json.load(open(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d45809",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = OCRDataset(root=root, transforms=None)\n",
    "img, target = x.__getitem__(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef037ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5421f0",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(num__keypoints):\n",
    "    \n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,\n",
    "                                                                   pretrained_backbone=True,\n",
    "                                                                   num_keypoints=num_keypoints,\n",
    "                                                                   num_classes=5,\n",
    "                                                                   trainable_backbone_layers=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082cee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # train on the GPU or on the CPU, if a GPU is not available\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # our dataset has two classes only - background and person\n",
    "    num_classes = 5\n",
    "\n",
    "    # use our dataset and defined transformations\n",
    "    dataset = OCRDataset('path/to/images', get_transform(train=True))\n",
    "    dataset_test = OCRDataset('path/to/images', get_transform(train=False))\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    indices = torch.randperm(1073).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:1000])\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, indices[1000:1073])\n",
    "\n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=2, shuffle=True, num_workers=0,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model = get_keypoints(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # let's train it for 100 epochs\n",
    "    num_epochs = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "    \n",
    "    torch.save(model.state_dict(), 'ocr_keypoints.pth')\n",
    "\n",
    "    print(\"That's it!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92277eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "\n",
    "num = random.randrange(1073, 1341)\n",
    "img, _ = OCRDataset('path/to/images', get_transform(train=False))[num]\n",
    "\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(torch.device('cpu'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de71253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
