{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os      # Library for interacting with the operating system\n",
    "import time    # Library for tracking the time taken to perform a task\n",
    "import torch   # PyTorch library for building and training deep learning models\n",
    "import torchvision   # A PyTorch library containing popular datasets, model architectures, and image transformations\n",
    "import torchvision.transforms as transforms   # A module containing common image transformations\n",
    "import torch.nn as nn   # PyTorch library containing various neural network layers and functions\n",
    "from torch.nn import init   # A function for initializing the weights of a neural network\n",
    "from torch.optim import lr_scheduler   # A PyTorch module for implementing various learning rate scheduling strategies\n",
    "import functools   # A module providing various functions for higher-order programming\n",
    "import numpy as np   # A library for numerical computations\n",
    "import cv2 as cv   # OpenCV library for image and video processing\n",
    "from PIL import Image   # A library for image processing and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f77cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(directory):\n",
    "    \n",
    "    images = []  # create an empty list to store the image paths\n",
    "    \n",
    "    # check if the given directory is valid or not\n",
    "    assert os.path.isdir(directory), '%s is not a valid directory' % directory\n",
    "\n",
    "    # walk through the directory and subdirectories to find all image files\n",
    "    for root, _, fnames in sorted(os.walk(directory)):\n",
    "        for fname in fnames:\n",
    "            path = os.path.join(root, fname)  # get the full path of the image file\n",
    "            images.append(path)  # add the image path to the list of images\n",
    "    \n",
    "    return images  # return the list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __print_size_warning(ow, oh, w, h):\n",
    "    \n",
    "    if not hasattr(__print_size_warning, 'has_printed'):\n",
    "        \n",
    "        print(\"The image size needs to be a multiple of 4. \"\n",
    "              \"The loaded image size was (%d, %d), so it was adjusted to \"\n",
    "              \"(%d, %d). This adjustment will be done to all images \"\n",
    "              \"whose sizes are not multiples of 4\" % (ow, oh, w, h))\n",
    "        \n",
    "        __print_size_warning.has_printed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __make_power_2(img, base, method=Image.BICUBIC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Resizes the input image to the nearest size that is a power of 2. If the image size is already a power of 2, then the\n",
    "    original image is returned. Uses the PIL library for image resizing.\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image): Input image to resize.\n",
    "        base (int): Base size to round the image dimensions to.\n",
    "        method (int): Resampling method for image resizing. Default is Image.BICUBIC.\n",
    "\n",
    "    Returns:\n",
    "        (PIL.Image): Resized image.\n",
    "    \"\"\"\n",
    "    \n",
    "    ow, oh = img.size # Get the original width and height of the image.\n",
    "    h = int(round(oh / base) * base) # Calculate the new height by rounding the original height to the nearest multiple of the base size.\n",
    "    w = int(round(ow / base) * base) # Calculate the new width by rounding the original width to the nearest multiple of the base size.\n",
    "    \n",
    "    # If the new height and width are the same as the original height and width, return the original image.\n",
    "    if h == oh and w == ow:\n",
    "        return img\n",
    "\n",
    "    # Otherwise, print a warning about resizing the image.\n",
    "    __print_size_warning(ow, oh, w, h)\n",
    "    \n",
    "    # Resize the image to the new dimensions using the specified resampling method.\n",
    "    return img.resize((w, h), method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(method):\n",
    "    \n",
    "    \"\"\"\n",
    "    The get_transform function takes in a method argument and returns a PyTorch transform pipeline.\n",
    "\n",
    "    The transform pipeline consists of three transforms:\n",
    "\n",
    "    1. A custom lambda transform that resizes the image to the nearest multiple of 4 using the __make_power_2 function.\n",
    "    2. The ToTensor transform, which converts the image to a PyTorch tensor.\n",
    "    3. The Normalize transform, which normalizes the tensor values to have a mean of 0.5 and a standard deviation of 0.5 for each channel.\n",
    "    \n",
    "    Finally, the Compose transform is used to combine the individual transforms into a single pipeline.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to hold all the transforms\n",
    "    transform_list = []\n",
    "    \n",
    "    # Add a custom lambda transform that resizes the image to the nearest multiple of 4 using the __make_power_2 function\n",
    "    transform_list.append(transforms.Lambda(lambda img: __make_power_2(img, base=4, method=method)))\n",
    "\n",
    "    # Convert the image to a tensor\n",
    "    transform_list += [transforms.ToTensor()]\n",
    "    \n",
    "    # Normalize the image tensor\n",
    "    transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    \n",
    "    # Combine the transforms into a single pipeline using the transforms.Compose function and return it\n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net(net, gpu_ids, init_type='normal', init_gain=0.02):\n",
    "\n",
    "    # Check if any GPU is available and set the network to run on it\n",
    "    if gpu_ids[0] != -1:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "\n",
    "    # Function to initialize weights and biases of the network\n",
    "    def init_func(m): \n",
    "        \n",
    "        classname = m.__class__.__name__\n",
    "        \n",
    "        # For Conv and Linear layers, initialize weight with normal distribution and bias with constant 0\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "                \n",
    "        # For BatchNorm2d layers, initialize weight with normal distribution and bias with constant 0\n",
    "        elif classname.find('BatchNorm2d') != -1: \n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    # Apply the initialized function to the network\n",
    "    net.apply(init_func)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63367d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that reads aligned image pairs from the disk, where images in each pair have the same filename.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataroot, phase):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataroot (str): Root directory of the dataset.\n",
    "            phase (str): 'train' or 'test' phase.\n",
    "        \"\"\"\n",
    "        self.dataroot = dataroot\n",
    "        self.phase = phase\n",
    "        self.dir_AB = os.path.join(dataroot, phase)  # get the directory of the images\n",
    "        self.AB_paths = sorted(make_dataset(self.dir_AB))  # get the paths of the images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index of the pair of images.\n",
    "        Returns:\n",
    "            A dictionary containing the processed images and their paths.\n",
    "        \"\"\"\n",
    "        # Read an image pair given a random integer index\n",
    "        AB_path = self.AB_paths[index]\n",
    "        AB = Image.open(AB_path).convert('RGB')\n",
    "\n",
    "        # Split AB image into A and B AFTER HAVING BEEN PROCESSED FROM THE SCRIPT \"combine_A_and_B.py\"\n",
    "        w, h = AB.size\n",
    "        w2 = int(w / 2)\n",
    "        A = AB.crop((0, 0, w2, h))\n",
    "        B = AB.crop((w2, 0, w, h))\n",
    "\n",
    "        # Apply the same transform to both A and B\n",
    "        A_transform = get_transform(Image.BICUBIC)\n",
    "        B_transform = get_transform(Image.BICUBIC)\n",
    "\n",
    "        A = A_transform(A)\n",
    "        B = B_transform(B)\n",
    "\n",
    "        # Return the processed images and their paths as a dictionary\n",
    "        return {'A': A, 'B': B, 'A_paths': AB_path, 'B_paths': AB_path}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of image pairs.\n",
    "        \"\"\"\n",
    "        return len(self.AB_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        \n",
    "        # Build convolutional block\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \n",
    "        # Initialize empty list to store convolutional layers and padding\n",
    "        conv_block = []\n",
    "        \n",
    "        # Set padding size to 0 initially\n",
    "        p = 0\n",
    "        \n",
    "        # Add reflection padding layer to the convolutional block\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "        \n",
    "        # Add convolutional layer, normalization layer, and activation function to the convolutional block\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        \n",
    "        # If use_dropout flag is set to True, add dropout layer to the convolutional block\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "        \n",
    "        # Add reflection padding layer to the convolutional block\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "        \n",
    "        # Add convolutional layer and normalization layer to the convolutional block\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        # Return convolutional block as a sequential layer\n",
    "        return nn.Sequential(*conv_block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Add input tensor x with the convolutional block output\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        \n",
    "        # Return output tensor\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class named TestModel\n",
    "class TestModel:\n",
    "\n",
    "    # Initialize the class and create a generator network instance\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Create a ResnetGenerator instance with the specified hyperparameters\n",
    "        self.netG = ResnetGenerator(input_nc=3, output_nc=3, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=True, n_blocks=9, padding_type='reflect')\n",
    "        \n",
    "    # Set the input for the network, which in this case is an image\n",
    "    def set_input(self, input):\n",
    "        \n",
    "        # Set the real image tensor to the input image tensor passed in and move it to the CPU\n",
    "        self.real = input['A'].to(torch.device('cpu'))\n",
    "        \n",
    "        # Set the image path to the input image path passed in\n",
    "        self.image_paths = input['A_path']\n",
    "\n",
    "    # Forward pass through the generator network\n",
    "    def forward(self):\n",
    "  \n",
    "        # Generate a fake image using the input image\n",
    "        self.fake = self.netG(self.real)\n",
    "        \n",
    "        # Return the generated fake image tensor\n",
    "        return self.fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dataset object\n",
    "dataset = AlignedDataset('path/to/test', 'test_run')\n",
    "\n",
    "# Defining the Dataloader\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of Model\n",
    "\n",
    "# gpu_ids = [-1]\n",
    "pix2pix = TestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32250d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = 'model_file.pth'\n",
    "# model_details = ResnetGenerator()\n",
    "model_details = torch.load(modelpath, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "# model = model_details['model']\n",
    "# model.load_state_dict(model_details['state_dict_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38515080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pix.netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over each batch of data\n",
    "for i, data in enumerate(data_loader):\n",
    "    \n",
    "    # Setting the input of the pix2pix object with the current batch of data\n",
    "    pix2pix.set_input(data) \n",
    "    \n",
    "    # Making a forward pass through the pix2pix object\n",
    "    with torch.no_grad():\n",
    "        pred = pix2pix.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51734500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted image tensor from the model output\n",
    "image_tensor = pred.data\n",
    "\n",
    "# Check the shape of the tensor\n",
    "image_tensor.shape\n",
    "\n",
    "# Get the first image tensor from the batch and convert it to a numpy array\n",
    "image_numpy = image_tensor[0].cpu().float().numpy()\n",
    "\n",
    "# Tile the numpy array across 3 channels\n",
    "image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "\n",
    "# Transpose the numpy array to get the channels as the last dimension and scale the pixel values to [0, 255]\n",
    "image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "\n",
    "# Convert the numpy array to an unsigned integer 8-bit array\n",
    "image_numpy = image_numpy.astype(np.uint8)\n",
    "\n",
    "# Save the numpy array as a PNG image\n",
    "# image_pil = Image.fromarray(image_numpy)\n",
    "image_numpy.save('result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a442a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
