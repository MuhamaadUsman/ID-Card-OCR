{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97661538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os      # Library for interacting with the operating system\n",
    "import time    # Library for tracking the time taken to perform a task\n",
    "import torch   # PyTorch library for building and training deep learning models\n",
    "import torchvision   # A PyTorch library containing popular datasets, model architectures, and image transformations\n",
    "import torchvision.transforms as transforms   # A module containing common image transformations\n",
    "import torch.nn as nn   # PyTorch library containing various neural network layers and functions\n",
    "from torch.nn import init   # A function for initializing the weights of a neural network\n",
    "from torch.optim import lr_scheduler   # A PyTorch module for implementing various learning rate scheduling strategies\n",
    "import functools   # A module providing various functions for higher-order programming\n",
    "import numpy as np   # A library for numerical computations\n",
    "import cv2 as cv   # OpenCV library for image and video processing\n",
    "from PIL import Image   # A library for image processing and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ae067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(directory):\n",
    "    \n",
    "    images = []  # create an empty list to store the image paths\n",
    "    \n",
    "    # check if the given directory is valid or not\n",
    "    assert os.path.isdir(directory), '%s is not a valid directory' % directory\n",
    "\n",
    "    # walk through the directory and subdirectories to find all image files\n",
    "    for root, _, fnames in sorted(os.walk(directory)):\n",
    "        for fname in fnames:\n",
    "            path = os.path.join(root, fname)  # get the full path of the image file\n",
    "            images.append(path)  # add the image path to the list of images\n",
    "    \n",
    "    return images  # return the list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __make_power_2(img, base, method=Image.BICUBIC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Resizes the input image to the nearest size that is a power of 2. If the image size is already a power of 2, then the\n",
    "    original image is returned. Uses the PIL library for image resizing.\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image): Input image to resize.\n",
    "        base (int): Base size to round the image dimensions to.\n",
    "        method (int): Resampling method for image resizing. Default is Image.BICUBIC.\n",
    "\n",
    "    Returns:\n",
    "        (PIL.Image): Resized image.\n",
    "    \"\"\"\n",
    "    \n",
    "    ow, oh = img.size # Get the original width and height of the image.\n",
    "    h = int(round(oh / base) * base) # Calculate the new height by rounding the original height to the nearest multiple of the base size.\n",
    "    w = int(round(ow / base) * base) # Calculate the new width by rounding the original width to the nearest multiple of the base size.\n",
    "    \n",
    "    # If the new height and width are the same as the original height and width, return the original image.\n",
    "    if h == oh and w == ow:\n",
    "        return img\n",
    "\n",
    "    # Otherwise, print a warning about resizing the image.\n",
    "    __print_size_warning(ow, oh, w, h)\n",
    "    \n",
    "    # Resize the image to the new dimensions using the specified resampling method.\n",
    "    return img.resize((w, h), method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __print_size_warning(ow, oh, w, h):\n",
    "    \n",
    "    if not hasattr(__print_size_warning, 'has_printed'):\n",
    "        \n",
    "        print(\"The image size needs to be a multiple of 4. \"\n",
    "              \"The loaded image size was (%d, %d), so it was adjusted to \"\n",
    "              \"(%d, %d). This adjustment will be done to all images \"\n",
    "              \"whose sizes are not multiples of 4\" % (ow, oh, w, h))\n",
    "        \n",
    "        __print_size_warning.has_printed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7efc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(method):\n",
    "    \n",
    "    \"\"\"\n",
    "    The get_transform function takes in a method argument and returns a PyTorch transform pipeline.\n",
    "\n",
    "    The transform pipeline consists of three transforms:\n",
    "\n",
    "    1. A custom lambda transform that resizes the image to the nearest multiple of 4 using the __make_power_2 function.\n",
    "    2. The ToTensor transform, which converts the image to a PyTorch tensor.\n",
    "    3. The Normalize transform, which normalizes the tensor values to have a mean of 0.5 and a standard deviation of 0.5 for each channel.\n",
    "    \n",
    "    Finally, the Compose transform is used to combine the individual transforms into a single pipeline.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a list to hold all the transforms\n",
    "    transform_list = []\n",
    "    \n",
    "    # Add a custom lambda transform that resizes the image to the nearest multiple of 4 using the __make_power_2 function\n",
    "    transform_list.append(transforms.Lambda(lambda img: __make_power_2(img, base=4, method=method)))\n",
    "\n",
    "    # Convert the image to a tensor\n",
    "    transform_list += [transforms.ToTensor()]\n",
    "    \n",
    "    # Normalize the image tensor\n",
    "    transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    \n",
    "    # Combine the transforms into a single pipeline using the transforms.Compose function and return it\n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ee880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net(net, gpu_ids, init_type='normal', init_gain=0.02):\n",
    "\n",
    "    # Check if any GPU is available and set the network to run on it\n",
    "    if gpu_ids[0] != -1:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
    "\n",
    "    # Function to initialize weights and biases of the network\n",
    "    def init_func(m): \n",
    "        \n",
    "        classname = m.__class__.__name__\n",
    "        \n",
    "        # For Conv and Linear layers, initialize weight with normal distribution and bias with constant 0\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "                \n",
    "        # For BatchNorm2d layers, initialize weight with normal distribution and bias with constant 0\n",
    "        elif classname.find('BatchNorm2d') != -1: \n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    # Apply the initialized function to the network\n",
    "    net.apply(init_func)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, epoch_count, n_epochs, n_epochs_decay):\n",
    "    \n",
    "    # Define a lambda function for the learning rate scheduler\n",
    "    def lambda_rule(epoch):\n",
    "        lr_l = 1.0 - max(0, epoch + epoch_count - n_epochs) / float(n_epochs_decay + 1)\n",
    "        return lr_l\n",
    "    \n",
    "    # Create a LambdaLR scheduler that uses the lambda_rule function\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    \n",
    "    # Return the scheduler object\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f392da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(nets, requires_grad=False):\n",
    "    \n",
    "    # Check if the input 'nets' is a list or a single network\n",
    "    if not isinstance(nets, list):\n",
    "        nets = [nets]\n",
    "    \n",
    "    # Loop through all the networks in the list\n",
    "    for net in nets:\n",
    "        \n",
    "        # Check if the current network is not None\n",
    "        if net is not None:\n",
    "            \n",
    "            # Loop through all the parameters of the current network\n",
    "            for param in net.parameters():\n",
    "                \n",
    "                # Set the requires_grad attribute of the current parameter to the specified value\n",
    "                param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        \n",
    "        # Build convolutional block\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \n",
    "        # Initialize empty list to store convolutional layers and padding\n",
    "        conv_block = []\n",
    "        \n",
    "        # Set padding size to 0 initially\n",
    "        p = 0\n",
    "        \n",
    "        # Add reflection padding layer to the convolutional block\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "        \n",
    "        # Add convolutional layer, normalization layer, and activation function to the convolutional block\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        \n",
    "        # If use_dropout flag is set to True, add dropout layer to the convolutional block\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "        \n",
    "        # Add reflection padding layer to the convolutional block\n",
    "        conv_block += [nn.ReflectionPad2d(1)]\n",
    "        \n",
    "        # Add convolutional layer and normalization layer to the convolutional block\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        # Return convolutional block as a sequential layer\n",
    "        return nn.Sequential(*conv_block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Add input tensor x with the convolutional block output\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        \n",
    "        # Return output tensor\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247be7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=True, n_blocks=9, padding_type='reflect'):\n",
    "        # input_nc: number of input channels\n",
    "        # output_nc: number of output channels\n",
    "        # ngf: number of filters in the generator's first conv layer\n",
    "        # norm_layer: normalization layer (default=nn.BatchNorm2d)\n",
    "        # use_dropout: whether to use dropout layers (default=True)\n",
    "        # n_blocks: number of ResNet blocks in the generator (default=9)\n",
    "        # padding_type: type of padding used in conv layers (default='reflect')\n",
    "\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "\n",
    "        # By default, don't use bias in conv layers\n",
    "        use_bias = False\n",
    "\n",
    "        # Build the generator model using a list to store the layers\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),  # Pad the input with reflection padding\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),  # First convolutional layer\n",
    "            norm_layer(ngf),  # Apply normalization\n",
    "            nn.ReLU(True)  # Apply activation function (ReLU)\n",
    "        ]\n",
    "\n",
    "        n_downsampling = 2  # Number of downsampling layers\n",
    "        for i in range(n_downsampling):  # Add downsampling layers\n",
    "            mult = 2 ** i  # Multiplier for the number of filters\n",
    "            model += [\n",
    "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                norm_layer(ngf * mult * 2),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        mult = 2 ** n_downsampling  # Multiplier for the number of filters\n",
    "        for i in range(n_blocks):  # Add ResNet blocks\n",
    "            model += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)\n",
    "            ]\n",
    "\n",
    "        for i in range(n_downsampling):  # Add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)  # Multiplier for the number of filters\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                   kernel_size=3, stride=2,\n",
    "                                   padding=1, output_padding=1,\n",
    "                                   bias=use_bias),\n",
    "                norm_layer(int(ngf * mult / 2)),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        # Add final layers to generate output image\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),  # Pad output with reflection padding\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),  # Last convolutional layer\n",
    "            nn.Tanh()  # Apply Tanh activation function to generate output image\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)  # Store the generator model as a nn.Sequential module\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through the generator model\n",
    "\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e964886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "\n",
    "        use_bias = False  # Whether to use bias in convolutions\n",
    "\n",
    "        kw = 4  # Kernel size\n",
    "        padw = 1  # Padding size\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        # Add first convolutional layer followed by a leaky ReLU activation function\n",
    "\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            # gradually increase the number of filters by a factor of 2\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                # Add a convolutional layer with the specified number of filters, kernel size, stride, padding, and bias\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                # Add a normalization layer\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "                # Add a leaky ReLU activation function\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            # Add a convolutional layer with the specified number of filters, kernel size, stride, padding, and bias\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            # Add a normalization layer\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "            # Add a leaky ReLU activation function\n",
    "        ]\n",
    "\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)\n",
    "            # Add a convolutional layer that outputs a single-channel prediction map\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass of the discriminator network\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2453730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "   \n",
    "    def __init__(self, gan_mode='lsgan', target_real_label=1.0, target_fake_label=0.0):\n",
    " \n",
    "        super(GANLoss, self).__init__()  # Call the constructor of the parent class\n",
    "\n",
    "        # Register the target labels as buffers\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        \n",
    "        self.gan_mode = gan_mode  # Store the GAN mode (LSGAN, etc.)\n",
    "\n",
    "        # Create a mean squared error loss function\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_target_tensor(self, prediction, target_is_real):\n",
    "        # Get the target tensor for the given prediction and target_is_real flag\n",
    "\n",
    "        if target_is_real:\n",
    "            # If the target is real, use the real_label buffer\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            # Otherwise, use the fake_label buffer\n",
    "            target_tensor = self.fake_label\n",
    "        # Expand the target tensor to have the same shape as the prediction tensor\n",
    "        return target_tensor.expand_as(prediction)\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        # Compute the GAN loss for the given prediction and target_is_real flag\n",
    "\n",
    "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
    "        # Compute the loss using the mean squared error loss function\n",
    "        loss = self.loss(prediction, target_tensor)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class that reads aligned image pairs from the disk, where images in each pair have the same filename.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataroot, phase):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataroot (str): Root directory of the dataset.\n",
    "            phase (str): 'train' or 'test' phase.\n",
    "        \"\"\"\n",
    "        self.dataroot = dataroot\n",
    "        self.phase = phase\n",
    "        self.dir_AB = os.path.join(dataroot, phase)  # get the directory of the images\n",
    "        self.AB_paths = sorted(make_dataset(self.dir_AB))  # get the paths of the images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index of the pair of images.\n",
    "        Returns:\n",
    "            A dictionary containing the processed images and their paths.\n",
    "        \"\"\"\n",
    "        # Read an image pair given a random integer index\n",
    "        AB_path = self.AB_paths[index]\n",
    "        AB = Image.open(AB_path).convert('RGB')\n",
    "\n",
    "        # Split AB image into A and B AFTER HAVING BEEN PROCESSED FROM THE SCRIPT \"combine_A_and_B.py\"\n",
    "        w, h = AB.size\n",
    "        w2 = int(w / 2)\n",
    "        A = AB.crop((0, 0, w2, h))\n",
    "        B = AB.crop((w2, 0, w, h))\n",
    "\n",
    "        # Apply the same transform to both A and B\n",
    "        A_transform = get_transform(Image.BICUBIC)\n",
    "        B_transform = get_transform(Image.BICUBIC)\n",
    "\n",
    "        A = A_transform(A)\n",
    "        B = B_transform(B)\n",
    "\n",
    "        # Return the processed images and their paths as a dictionary\n",
    "        return {'A': A, 'B': B, 'A_paths': AB_path, 'B_paths': AB_path}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of image pairs.\n",
    "        \"\"\"\n",
    "        return len(self.AB_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64614a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetDataLoader():\n",
    "    \n",
    "    def __init__(self, dataroot, phase):\n",
    "        \n",
    "        # Initialize the class with the given data root and phase\n",
    "        self.dataroot = dataroot\n",
    "        self.phase = phase\n",
    "        \n",
    "        # Create an instance of the AlignedDataset class using the given data root and phase\n",
    "        self.dataset = AlignedDataset(dataroot, phase)\n",
    "        \n",
    "        # Create a PyTorch DataLoader using the AlignedDataset instance\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        # Return the instance of the class\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        # Return the length of the AlignedDataset instance\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        # Loop through the DataLoader and yield the data for each batch\n",
    "        for i, data in enumerate(self.dataloader):\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82952cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixModel:\n",
    "    \n",
    "    \"\"\"Implementation of the Pix2Pix model.\"\"\"\n",
    "\n",
    "    def __init__(self, gpu_ids):\n",
    "        \n",
    "        \"\"\"Constructor method to initialize the model.\n",
    "\n",
    "        Args:\n",
    "            gpu_ids (list): List of GPU IDs to use. Use -1 for CPU.\n",
    "        \"\"\"\n",
    "        self.gpu_ids = gpu_ids\n",
    "        \n",
    "        # Set the device (GPU or CPU) to use for computations\n",
    "        self.device = torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids[0]!=-1 else torch.device('cpu')\n",
    "\n",
    "        # Create a list to hold the optimizer instances\n",
    "        self.optimizers = []\n",
    "        \n",
    "        # Create the generator network instance\n",
    "        self.netG = ResnetGenerator(\n",
    "            input_nc=3, output_nc=3, ngf=64,\n",
    "            norm_layer=nn.BatchNorm2d, use_dropout=True, n_blocks=9)\n",
    "        \n",
    "        # Initialize the generator network with a normal distribution and a standard deviation of 0.02\n",
    "        init_net(self.netG, gpu_ids, 'normal', 0.02)\n",
    "        \n",
    "        # Create the discriminator network instance\n",
    "        self.netD = NLayerDiscriminator(\n",
    "            input_nc=6, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d)\n",
    "        \n",
    "        # Initialize the discriminator network with a normal distribution and a standard deviation of 0.02\n",
    "        init_net(self.netD, gpu_ids, 'normal', 0.02)\n",
    "\n",
    "        # Set the GAN loss criterion and move it to the device (GPU or CPU) to use for computations\n",
    "        self.criterionGAN = GANLoss(gan_mode='lsgan').to(self.device)\n",
    "        \n",
    "        # Set the L1 loss criterion\n",
    "        self.criterionL1 = torch.nn.L1Loss()\n",
    "\n",
    "        # Create an Adam optimizer instance for the generator network\n",
    "        self.optimizer_G = torch.optim.Adam(\n",
    "            self.netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Create an Adam optimizer instance for the discriminator network\n",
    "        self.optimizer_D = torch.optim.Adam(\n",
    "            self.netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Add the optimizer instances to the list\n",
    "        self.optimizers.append(self.optimizer_G)\n",
    "        self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        \n",
    "        \"\"\"Set the input data for the model.\n",
    "\n",
    "        Args:\n",
    "            input (dict): Dictionary containing the input data. The dictionary should have\n",
    "                the following keys:\n",
    "                - A (tensor): The input tensor A.\n",
    "                - B (tensor): The input tensor B.\n",
    "                - A_paths (list): List of paths to the A input data.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input = input\n",
    "        \n",
    "        # Move the input tensor A to the device (GPU or CPU) to use for computations\n",
    "        self.real_A = input['A'].to(self.device)\n",
    "        \n",
    "        # Move the input tensor B to the device (GPU or CPU) to use for computations\n",
    "        self.real_B = input['B'].to(self.device)\n",
    "        \n",
    "        # Get the paths to the input data\n",
    "        self.image_paths = input['A_paths']\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        \"\"\"Perform a forward pass through the generator network.\"\"\"\n",
    "        \n",
    "        # Generate fake tensor B from the input tensor A\n",
    "        self.fake_B = self.netG(self.real_A)\n",
    "\n",
    "\n",
    "    def backward_D(self):\n",
    "\n",
    "        # Concatenate real_A and fake_B tensor along the 2nd axis\n",
    "        fake_AB = torch.cat((self.real_A, self.fake_B), 1) \n",
    "\n",
    "        # Pass fake_AB tensor through discriminator network (netD)\n",
    "        pred_fake = self.netD(fake_AB.detach())\n",
    "\n",
    "        # Compute the GAN loss for discriminator (loss_D_fake) using the predicted\n",
    "        # output from discriminator (pred_fake) and the target value of \"False\"\n",
    "        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "\n",
    "        # Concatenate real_A and real_B tensor along the 2nd axis\n",
    "        real_AB = torch.cat((self.real_A, self.real_B), 1)\n",
    "\n",
    "        # Pass real_AB tensor through discriminator network (netD)\n",
    "        pred_real = self.netD(real_AB)\n",
    "\n",
    "        # Compute the GAN loss for discriminator (loss_D_real) using the predicted\n",
    "        # output from discriminator (pred_real) and the target value of \"True\"\n",
    "        self.loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        # Compute the final GAN loss for discriminator (loss_D) by taking the average of\n",
    "        # loss_D_fake and loss_D_real and multiplying it by 0.5\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "\n",
    "        # Compute gradients of loss_D and update parameters of netD\n",
    "        self.loss_D.backward()\n",
    "\n",
    "        # Return the losses (loss_D_real, loss_D_fake)\n",
    "        return (self.loss_D_real, self.loss_D_fake)\n",
    "\n",
    "\n",
    "    def backward_G(self):\n",
    "\n",
    "        # Concatenate real_A and fake_B tensor along the 2nd axis\n",
    "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n",
    "\n",
    "        # Pass fake_AB tensor through discriminator network (netD)\n",
    "        pred_fake = self.netD(fake_AB)\n",
    "\n",
    "        # Compute the GAN loss for generator (loss_G_GAN) using the predicted\n",
    "        # output from discriminator (pred_fake) and the target value of \"True\"\n",
    "        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # Compute the L1 loss between fake_B and real_B and multiply it by 100.0\n",
    "        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * 100.0\n",
    "\n",
    "        # Compute the final loss for generator (loss_G) by adding loss_G_GAN and loss_G_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "\n",
    "        # Compute gradients of loss_G and update parameters of generator network\n",
    "        self.loss_G.backward()\n",
    "\n",
    "        # Return the losses (loss_G_GAN, loss_G_L1)\n",
    "        return (self.loss_G_GAN, self.loss_G_L1)\n",
    "\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "\n",
    "        # Perform forward pass to compute intermediate outputs\n",
    "        self.forward()              \n",
    "\n",
    "        # Enable gradient computation for discriminator network (netD)\n",
    "        set_requires_grad(nets=self.netD, requires_grad=True)       \n",
    "        \n",
    "        # Reset gradients of optimizer for discriminator network (optimizer_D)\n",
    "        self.optimizer_D.zero_grad()     \n",
    "        \n",
    "        # Compute the backward pass for discriminator\n",
    "        rf_losses = self.backward_D()       \n",
    "        \n",
    "        # Update the parameters of the discriminator network\n",
    "        self.optimizer_D.step()    \n",
    "\n",
    "        # Disable gradient computation for discriminator network (netD)\n",
    "        set_requires_grad(nets=self.netD, requires_grad=False)  \n",
    "        \n",
    "        # Reset gradients of optimizer for generator network (optimizer_G)\n",
    "        self.optimizer_G.zero_grad()        \n",
    "       \n",
    "        gl_losses = self.backward_G()                 \n",
    "        self.optimizer_G.step() \n",
    "        \n",
    "        return (rf_losses, gl_losses, self.optimizer_G, self.optimizer_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CustomDatasetDataLoader('D:/Data Science Projects/CNIC OCR/GANs/pytorch-CycleGAN-and-pix2pix-master/datasets/cnictopix', 'train')\n",
    "dataset = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of Model\n",
    "\n",
    "gpu_ids = [-1]\n",
    "pix2pix = Pix2PixModel(gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c04ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting epoch count to 1\n",
    "epoch_count = 1\n",
    "\n",
    "# Set the total number of epochs to 1\n",
    "n_epochs = 1\n",
    "\n",
    "# Set the number of epochs to linearly decay the learning rate over to 1\n",
    "n_epochs_decay = 1\n",
    "\n",
    "# Create a list of schedulers for each optimizer in the 'pix2pix.optimizers' list\n",
    "# The 'get_scheduler' function is called for each optimizer with the following arguments:\n",
    "#   - The optimizer object itself\n",
    "#   - The starting epoch count\n",
    "#   - The total number of epochs\n",
    "#   - The number of epochs to decay the learning rate over\n",
    "# The resulting schedulers are stored in a list called 'schedulers'\n",
    "\n",
    "schedulers = [get_scheduler(optimizer, epoch_count, n_epochs, n_epochs_decay) for optimizer in pix2pix.optimizers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ab3b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_iters = 0   # Initialize the total number of iterations to 0\n",
    "\n",
    "for epoch in range(epoch_count, n_epochs + n_epochs_decay + 1):\n",
    "    # Loop over the epochs, starting with the current epoch count and going up to n_epochs + n_epochs_decay\n",
    "    \n",
    "    epoch_start_time = time.time()  # Record the start time of the current epoch\n",
    "    \n",
    "    epoch_iter = 0  # Initialize the number of iterations for the current epoch to 0\n",
    "    \n",
    "    print(\"Epoch Number on Training: \", epoch, '\\n')  # Print the current epoch number\n",
    "    \n",
    "    old_lr = pix2pix.optimizers[0].param_groups[0]['lr']  # Get the learning rate of the first optimizer in pix2pix\n",
    "    \n",
    "    for scheduler in schedulers:  # Loop over the schedulers\n",
    "        scheduler.step()  # Take a scheduler step to update the learning rates of the optimizers\n",
    "        \n",
    "    lr = pix2pix.optimizers[0].param_groups[0]['lr']  # Get the new learning rate of the first optimizer\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        # Loop over the data in the dataset, keeping track of the index of the current iteration\n",
    "        \n",
    "        total_iters += 1  # Increment the total number of iterations\n",
    "        \n",
    "        epoch_iter += 1  # Increment the number of iterations for the current epoch\n",
    "        \n",
    "        pix2pix.set_input(data)  # Set the input data for the pix2pix model\n",
    "        \n",
    "        (rf_losses, gl_losses, opt_G, opt_D) = pix2pix.optimize_parameters()  # Optimize the parameters of the pix2pix model\n",
    "        \n",
    "        losses = [float(gl_losses[0].item()), float(gl_losses[1].item()), float(rf_losses[0].item()), float(rf_losses[1].item())]\n",
    "        # Get the losses for the current iteration\n",
    "        \n",
    "        print('Losses for Epoch number ', epoch, ' for iteration ', i+1 , ' are G_GAN:', losses[0], ', G_L1:', losses[1], ', D_real:', losses[2], ', D_fake:', losses[3], '\\n')\n",
    "        # Print the losses for the current iteration\n",
    "        \n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_G': pix2pix.netG.state_dict(),\n",
    "                'model_D': pix2pix.netD.state_dict(),\n",
    "                'optimizer_G_state_dict': opt_G.state_dict(),\n",
    "                'optimizer_D_state_dict': opt_D.state_dict(),\n",
    "                'loss_G_GAN': float(gl_losses[0].item()),\n",
    "                'loss_G_L1': float(gl_losses[1].item()),\n",
    "                'loss_D_real': float(rf_losses[0].item()),\n",
    "                'loss_D_fake': float(rf_losses[0].item())}, 'model.pth')\n",
    "    # Save the current state of the pix2pix model, optimizers, and losses to a file\n",
    "    \n",
    "print('Total time taken for training data on ', epoch, 's is: ', time.time() - epoch_start_time)\n",
    "# Print the total time taken to train the data for all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946e812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f9b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
